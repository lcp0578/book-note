## 第2章 海量数据采集
- 数据形态
	- **结构化数据**：数据规则且完整，是由二维表结构来逻辑表达和实现的数据，严格地遵循数据格式与长度规范。
		- 常见的结构化数据有关系型数据库中的数据、Excel中的数据等。
	- **半结构化数据**：数据规则且完整，同样严格地遵循数据格式与长度规范，但无法通过二维表结构来表现。
		- 常见的半结构化数据有JSON、XML等格式的复杂结构。
	- **非结构化数据**：数据结构不规则或不完整，不方便用二维表结构来表现，需要经过复杂的逻辑处理才能提取其中的信息内容。
		- 常见的非结构化数据有网页数据、图谱、声音和视频等。
- 数据来源
	- **日志数据**：包括通过客户端埋点、服务端埋点等方式采集的系统日志和业务日志数据等。
		- 这些数据被采集过来之后可以反哺业务，为后期的运营和决策提供数据支撑。
	- **数据库数据**：包括业务系统数据、订单数据、用户个人信息数据等。
		- 传统的业务数据存储基本上都是依赖数据库(MySQL、Oracle等)进行存储，企业在进行数据转型期间，需要将传统的数据库中的数据迁移到大数据平台中。
	- **网页数据**：包括互联网网页中的新闻、博客等数据。
		- 当企业内部信息不足时，可以考虑利用外部互联网数据进行一些“化学反应”，即将外部的数据和内部的数据进行有效融合，从而让内部数据在应用上有很多价值。
	- **物联网数据**：包括通过传感器、摄像头、Wifi探针等智能硬件采集到的数据。
		- 常见的采集方式有Wifi信号采集、信令数据采集、图像视频采集，以及传感器探测等。
- 数据采集规则
	- 离线采集
		- 全量采集
		- 增量采集
	- 实时采集
- 日志数据采集工具
	- Flume、Logstash和Filebeat对比

		<table>
			<tr>
				<th>对比项</th>
				<th>Flume</th>	
				<th>Logstash</th>
				<th>Filebeat</th>
			</tr>
			<tr>
				<td>来源</td>
				<td>Apache</td>
				<td>Elastic</td>
				<td>Elastic</td>
			</tr>
			<tr>
				<td>开发语言</td>
				<td>Java</td>
				<td>JRuby</td>
				<td>Go</td>
			</tr>
			<tr>
				<td>内存消耗</td>
				<td>高</td>
				<td>高</td>
				<td>低</td>
			</tr>
			<tr>
				<td>CPU消耗</td>
				<td>高</td>
				<td>高</td>
				<td>低</td>
			</tr>
			<tr>
				<td>容错性</td>
				<td>优秀，内部有事务机制</td>
				<td>优秀，内部有持久化队列</td>
				<td>无</td>
			</tr>
			<tr>
				<td>负载均衡</td>
				<td>支持</td>
				<td>支持</td>
				<td>支持</td>
			</tr>
			<tr>
				<td>插件</td>
				<td>丰富的输入和输出插件</td>
				<td>丰富的输入和输出插件</td>
				<td>只支持文件数据采集</td>
			</tr>
			<tr>
				<td>数据过滤能力</td>
				<td>提供了拦截器</td>
				<td>强大的过滤能力</td>
				<td>有过滤能力，但较弱</td>
			</tr>
			<tr>
				<td>二次开发难度</td>
				<td>容易，对Java程序员友好</td>
				<td>难</td>
				<td>难</td>
			</tr>
			<tr>
				<td>社区活跃度</td>
				<td>高</td>
				<td>高</td>
				<td>高</td>
			</tr>
			<tr>
				<td>资料完整度</td>
				<td>高</td>
				<td>高</td>
				<td>高</td>
			</tr>
		</table>
- Flume的原理及架构分析
	- Flume是一个很靠谱、很方便、很强的日志采集工具。它是目前大数据领域最常用的一个数据采集框架。
	- Flume具备3大特性：
		- 有一个简单、灵活、基于流的数据流结构。
		- 具有负载均衡机制和故障转移机制，能保证数据采集的稳定性和可靠性。
		- 具有一个简单可扩展的数据模型（Source、Channel和Sink）
	- Flume的典型应用场景是：采集应用程序运行期间产生的日志数据，并将多台机器中采集的日志数据汇总输出到指定目的地。
- Logstash原理及架构分析
	- Logstash是Elastic公司开源的收集、解析和转换日志的工具，可以方便地把分散的、多样化的日志收集起来，然后进行自定义处理，最后将其传输到指定的目的地。
	- Logstash常被用于在日志关系中作为日志采集设备，最常被用于ELK(Elasticsearch + Logstash + Kibana)中作为日志收集器。
	- Logstash收集日志的基本流程是：Input -> Filter -> Output。
	- Logstash的典型应用场景是和ELK结合在一起使用，其可以采集服务器运行期间产生的日志数据和应用程序产生的异常日志数据。
- Filebeat的原理及架构分析
	- Filebeat是日志文件的轻量级采集工具。Filebeat监控你指定的日志文件或位置，收集日志时间，并将它们转发给Elasticsearch或Logstash。
- 数据库数据采集工具
	- 数据库离线数据采集工具
		- Sqoop：由Apache开源的一个可以将Hadoop和关系数据库中的数据相互转移的工具，可以将关系型数据库（例如MySQL、Oracle等）中的数据导入Hadoop，也可以将Hadoop中的数据导出到关系型数据库中。
		- DataX：由阿里巴巴开源的一个异构数据源离线同步工具，用于实现包括关系型数据库（例如MySQL、Oracle）、HDFS、Hive、HBase、FTP等各种异构数据源之间稳定且高效的数据同步。
	- 数据库实施数据采集工具
		- Cannal：由阿里巴巴开源的一个基于MySQL数据库的增量日志(Binary Log)解析工具，可以提供增量数据订阅和消费，支持将MySQL中的增量数据采集到Kafka、RebbitMQ、ElasticSearch及HBase中。
		- Maxwell：由Zendesk开源的一个基于MySQL数据库的增量日志（Binart Log）解析工具，可以将MySQL中的增量数据以JSON格式写入Kafka、Kinesis、RabbitMQ及Redis中。
- 消息队列中间件
	- 为什么需要消息队列中间件
		- 应用解耦
			- 系统的耦合性越高，维护性和扩展性就越低。使用消息队列中间件解耦后，系统的维护性和扩展性就会提高。
		- 异步执行
			- 对于一些没有前后依赖关系的业务计算逻辑，不要使用同步的方式执行，这样太浪费时间。可考虑使用异步的方式执行，加快响应速度。
		- 流量削峰
			- 系统遇到用户请求流量的瞬间峰值，有可能会被压垮。使用消息队列中间件可以将大量用户请求缓存起来，系统可以根据自身的最大处理能力从消息队列中间件中主动消费数据进行处理，这样可以大大提高系统的稳定性。